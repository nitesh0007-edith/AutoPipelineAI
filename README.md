# ğŸ¤– AutoPipelineAI

**An LLM-Driven Agentic Framework for Autonomous ETL and DataOps**  
Designed and built by [Nitesh Ranjan Singh](https://github.com/nitesh0007-edith)

---

## ğŸš€ Project Summary

AutoPipelineAI is an open-source, end-to-end **LLM + Agentic AI powered data engineering framework** that automates ETL workflows, performs intelligent data operations, and enables natural language querying over structured and unstructured data. It integrates:

- ğŸ§  **LLMs (GPT/Mistral)** for understanding business context
- ğŸ”— **LangChain / CrewAI / LangGraph** for agentic decision-making
- ğŸ§¼ **Automated ETL Pipelines** using Python + Pandas
- ğŸ“Š **Streamlit dashboards** for user interaction
- ğŸ“„ **Multimodal data ingestion** (CSV, PDF, logs)
- âœ… **Schema validation + profiling** for DataOps
- ğŸ” Fully extensible + runs locally (no cloud dependency)

---

## ğŸ§± Project Architecture

User Query â†’ Streamlit UI
â†“
LangChain Agent (LLM)
â†“
Intelligently Routes To:

ETL Module (Extract + Transform)

Data Validation + Profiling

Semantic Search

Data Pipeline Generator
â†“
Returns Cleaned, Filtered, or Queried Data


---

## ğŸ—‚ï¸ Phases Overview

### âœ… Phase 1: Project Initialization

- ğŸ—ï¸ Project folder structure set up with `venv`, `src/`, `data/`, and `main.py`
- ğŸ“¦ Requirements listed for easy reproducibility
- ğŸ”’ `.gitignore` created to exclude logs, virtualenv, cache, etc.

---

### âœ… Phase 2: ETL Foundation & Local Ingestion

- ğŸ“ Ingested sample Superstore dataset (`input_docs/Sample - Superstore.csv`)
- ğŸ§¹ Cleaned data saved to `data/processed/`
- ğŸªµ Logging via `loguru`
- ğŸ“Š Streamlit interface for manual data triggers

---

### âœ… Phase 2B: Enhancements for DataOps

- ğŸ“ˆ **Automatic profiling** via `ydata-profiling`
  - Outputs interactive HTML reports (`data/reports/superstore_profile.html`)
- ğŸ“† **Date & Region filtering** via Streamlit inputs
- ğŸ” **Schema validator** to check column sanity before transformation

---

### ğŸ”œ Phase 3: LLM + Agentic Pipeline (Upcoming)

- ğŸ¤– LLM-enabled agent (using LangChain / CrewAI)
- ğŸ“Œ User types queries like:
  - *â€œShow me sales trend in West for January 2021â€*
  - *â€œWhat products drive profit in Furniture category?â€*
- ğŸ“„ LLM parses â†’ selects ETL functions â†’ executes â†’ returns answers
- ğŸ“˜ PDF/Log Ingestion + NER for documents and audit logs

---

## ğŸ“¸ UI Preview (Streamlit)

| Upload Data | Profiling | Filters |
|-------------|-----------|---------|
| ![upload](https://imgur.com/upload_sample.png) | ![profile](https://imgur.com/profile_sample.png) | ![filters](https://imgur.com/filters_sample.png) |

---

## ğŸ› ï¸ Tech Stack

| Tool           | Purpose                                  |
|----------------|------------------------------------------|
| Python (3.10+) | Core logic + ETL                         |
| Streamlit      | UI + User interaction                    |
| Pandas         | DataFrame operations                     |
| Loguru         | Smart logging                            |
| ydata-profiling| Auto EDA profiling                       |
| LangChain / CrewAI | LLM & agentic decision-making      |

---

## ğŸ§ª Local Setup

```bash
git clone https://github.com/nitesh0007-edith/AutoPipelineAI.git
cd AutoPipelineAI
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
streamlit run main.py

ğŸ§  Upcoming Features
LLM-based dynamic ETL generation

CrewAI/LangGraph-based task routing

Document/question answering from PDFs, logs, dashboards

Integration with SQLite or DuckDB for query layer

ğŸ‘¨â€ğŸ’» Author
Nitesh Ranjan Singh

Analyst (Data Engineer) @ IQVIA | MSc Data Science (University of Glasgow)

---

## âœ… To Use